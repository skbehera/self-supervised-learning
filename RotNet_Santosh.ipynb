{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bd3cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input,decode_predictions\n",
    "from keras.layers import Dense, Activation, Flatten, concatenate\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import load_img\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a71162",
   "metadata": {},
   "source": [
    "# Start Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e33b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######dataset contains diff. flower dataset folders ##### \n",
    "##### ( due to low resource I have used only three flower dataset, we can use more also, only need to put in that dataset folder)\n",
    "\n",
    "\n",
    "############## Now Load dataset ##############################\n",
    "\n",
    "def load_dataset(dataset='dataset'):\n",
    "    PATH = os.getcwd()\n",
    "    # Define data path\n",
    "    PATH = \"/content/drive/My Drive/Colab Notebooks\"\n",
    "    data_path = PATH + '/'+ dataset    \n",
    "    data_dir_list = os.listdir(data_path)\n",
    "    class_names = []\n",
    "    img_data_list=[]\n",
    "    labels = []\n",
    "    for dataset in data_dir_list:\n",
    "        class_names.append(dataset)\n",
    "        img_list=os.listdir(data_path+'/'+ dataset)\n",
    "        print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "        lb = len(class_names)-1\n",
    "        for img in img_list:\n",
    "            img_path = data_path + '/'+ dataset + '/'+ img\n",
    "            img = load_img(img_path, target_size=(224, 224))\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)            \n",
    "            x = x/255            \n",
    "            img_data_list.append(x)\n",
    "            labels.append(lb)\n",
    "    img_data = np.array(img_data_list)    \n",
    "    img_data=np.rollaxis(img_data,1,0)    \n",
    "    img_data=img_data[0]\n",
    "    print (img_data.shape)\n",
    "    labels=np.array(labels)\n",
    "    print(labels.shape)\n",
    "    num_classes = len(class_names)\n",
    "    return img_data, labels, class_names\n",
    "img_data, labels, class_names = load_dataset(dataset='dataset')\n",
    "\n",
    "############## it returns img_data, labels and class_names ##############################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f5d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Now creates pseduo labels for the dataset ##############################\n",
    "\n",
    "def rotate_img(img, rot):\n",
    "    if rot == 0:  # 0 degrees rotation\n",
    "        return img\n",
    "    elif rot == 90:  # 90 degrees rotation\n",
    "        return np.flipud(np.transpose(img, (1, 0, 2)))\n",
    "    elif rot == 180:  # 90 degrees rotation\n",
    "        return np.fliplr(np.flipud(img))\n",
    "    elif rot == 270:  # 270 degrees rotation / or -90\n",
    "        return np.transpose(np.flipud(img), (1, 0, 2))\n",
    "\n",
    "def rot_data(img_data):\n",
    "    rot_img_data = []\n",
    "    rot_labels = []\n",
    "    for img in img_data:\n",
    "        img_1 = rotate_img(img,0)\n",
    "        rot_img_data.append(img_1)\n",
    "        rot_labels.append(0)\n",
    "        img_2 = rotate_img(img,90)\n",
    "        rot_img_data.append(img_2)\n",
    "        rot_labels.append(1)\n",
    "        img_3 = rotate_img(img,180)\n",
    "        rot_img_data.append(img_3)\n",
    "        rot_labels.append(2)\n",
    "        img_4 = rotate_img(img,270)\n",
    "        rot_img_data.append(img_4)\n",
    "        rot_labels.append(3)\n",
    "        #print(rot_img_data.shape,rot_labels.shape)\n",
    "        #break\n",
    "    rot_img_data = np.array(rot_img_data)\n",
    "    #rot_labels = np_utils.to_categorical(rot_labels, 4)    \n",
    "    return rot_img_data, rot_labels\n",
    "\n",
    "rot_img_data, rot_labels = rot_data(img_data)\n",
    "\n",
    "##############  it returns rotation_img_data, pseduo labels (0,1,2,3)  ########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd89bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_labels = np.array(rot_labels)\n",
    "#### we can plot the data and see by ourselves\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(1,figsize=(12,12))\n",
    "for i in range(4):\n",
    "  plt.subplot(4,4,i+1)\n",
    "  plt.tight_layout()\n",
    "  #x[i] = x[i][:,:,::-1] # converting BGR to RGB\n",
    "  plt.imshow(rot_img_data[i][:,:,::-1], interpolation='none')\n",
    "  plt.title(\"class_label: {}\".format(rot_labels[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32f421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class psuedo labels to on-hot encoding\n",
    "X_psuedo_data = rot_img_data\n",
    "Y_psuedo_labels = np_utils.to_categorical(rot_labels, 4)  #  labels: (0,90,180,270) (0,1,2,3) ==> 4 classes\n",
    "num_classes = (Y_psuedo_labels.shape)[1]\n",
    "print(X_psuedo_data.shape,Y_psuedo_labels.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e78837",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# down load VGG 16 model to use in rotnet\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "model = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca7908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########   Model structured as per our class size  ###################################\n",
    "last_layer = model.get_layer('fc2').output\n",
    "#x= Flatten(name='flatten')(last_layer)\n",
    "out = Dense(num_classes, activation='softmax', name='output')(last_layer)\n",
    "custom_vgg_model = Model(image_input, out)\n",
    "custom_vgg_model.summary()\n",
    "\n",
    "for layer in custom_vgg_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "custom_vgg_model.layers[3].trainable\n",
    "\n",
    "custom_vgg_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "custom_vgg_model.summary()\n",
    "\n",
    "####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6575ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## Train the model with pseduo labels ######################################\n",
    "X = X_psuedo_data\n",
    "Y = Y_psuedo_labels\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5, random_state=2)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)\n",
    "hist = custom_vgg_model.fit(X_train, Y_train, batch_size=32, epochs=10, verbose=1, validation_data=(X_test, Y_test))\n",
    "(loss, accuracy) = custom_vgg_model.evaluate(X_test, Y_test, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae3aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## Save the trained model ######################################\n",
    "custom_vgg_model.save('RotNet_model')\n",
    "\n",
    "################################ upto this is for problem 1 #####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b376f5c",
   "metadata": {},
   "source": [
    "## Now strat for problem 2 #####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e092811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## Load the trained model ######################################\n",
    "from tensorflow import keras\n",
    "my_model = keras.models.load_model('RotNet_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ff10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_len = 4\n",
    "num_classes = class_len\n",
    "X = img_data\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "print(X.shape,Y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b529bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a51c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "layer_name = 'block5_pool'\n",
    "model2 = Model(inputs= my_model.input, outputs=my_model.get_layer(layer_name).output)\n",
    "model2.trainable = False\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd63f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### add some layer after pooling layers and take prediction layer as per the number of classes #####\n",
    "from tensorflow.keras import layers, models\n",
    "flatten_layer = layers.Flatten()\n",
    "dense_layer_1 = layers.Dense(50, activation='relu')\n",
    "dense_layer_2 = layers.Dense(20, activation='relu')\n",
    "prediction_layer = layers.Dense(num_classes, activation='softmax')\n",
    "model_super = models.Sequential([\n",
    "    model2,\n",
    "    flatten_layer,\n",
    "    dense_layer_1,\n",
    "    dense_layer_2,\n",
    "    prediction_layer\n",
    "])\n",
    "\n",
    "model_super.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceedc0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_super.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10be6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Train the model ##################################\n",
    "hist = model_super.fit(X_train, Y_train, batch_size=32, epochs=5, verbose=1, validation_data=(X_test, Y_test))\n",
    "#print('Training time: %s' % (t - time.time()))\n",
    "(loss, accuracy) = model_super.evaluate(X_test, Y_test, batch_size=32, verbose=1)\n",
    "\n",
    "print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e47fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_super.save('self-supervised_model')\n",
    "\n",
    "############## Finally save the model ##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abcec6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
